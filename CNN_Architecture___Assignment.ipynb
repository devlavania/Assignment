{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 1. What is the role of filters and feature maps in CNN?  \n",
        "**Answer:** Filters (kernels) detect local patterns like edges or textures. Feature maps are the outputs showing where those patterns occur in the input.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Explain padding and stride in CNNs. How do they affect output dimensions?  \n",
        "**Answer:**  \n",
        "- **Padding:** Adds zeros around input to preserve size and avoid losing border information.  \n",
        "- **Stride:** Step size of filter movement; larger stride reduces output size.  \n",
        "- **Effect:** Padding increases output dimensions, stride decreases them.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Define receptive field in CNNs. Why is it important?  \n",
        "**Answer:** The receptive field is the region of the input influencing a neuron’s activation. It’s important because deeper layers need larger receptive fields to capture global context and complex structures.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. How do filter size and stride influence parameters in a CNN?  \n",
        "**Answer:**  \n",
        "- **Filter size:** Larger kernels increase parameter count.  \n",
        "- **Stride:** Does not change parameters but alters output size, affecting computation in later layers.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Compare LeNet, AlexNet, and VGG.  \n",
        "**Answer:**  \n",
        "- **LeNet:** Shallow, small filters, good for digits (MNIST).  \n",
        "- **AlexNet:** Deeper, mixed filter sizes, introduced ReLU and dropout, breakthrough on ImageNet.  \n",
        "- **VGG:** Very deep (16–19 layers), uniform 3×3 filters, high accuracy but heavy computation.\n",
        "\n",
        "---\n",
        "\n",
        "### 10. End-to-end approach for chest X-ray classification (Normal vs Pneumonia).  \n",
        "**Answer:**  \n",
        "- **Data prep:** Resize, normalize, augment, handle imbalance with class weights.  \n",
        "- **Model:** CNN or transfer learning (e.g., ResNet/VGG) → ReLU hidden layers, sigmoid output.  \n",
        "- **Loss:** Binary cross-entropy (or focal loss for imbalance).  \n",
        "- **Optimizer:** Adam with early stopping and dropout to prevent overfitting.  \n",
        "- **Evaluation:** Use PR-AUC, ROC-AUC, precision/recall, confusion matrix.  \n",
        "- **Deployment:** Save trained model, build Streamlit app for image upload and prediction, ensure explainability (Grad-CAM) and secure hosting.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F8ziEhyCy8zL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnRiBc1Fy6hP",
        "outputId": "2ce6b444-21d8-4ae5-d65c-65e5c8ea92d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 102ms/step - accuracy: 0.8575 - loss: 0.4908 - val_accuracy: 0.9764 - val_loss: 0.0754\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 101ms/step - accuracy: 0.9801 - loss: 0.0646 - val_accuracy: 0.9868 - val_loss: 0.0404\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 105ms/step - accuracy: 0.9874 - loss: 0.0405 - val_accuracy: 0.9886 - val_loss: 0.0321\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 98ms/step - accuracy: 0.9903 - loss: 0.0322 - val_accuracy: 0.9894 - val_loss: 0.0322\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 101ms/step - accuracy: 0.9927 - loss: 0.0224 - val_accuracy: 0.9902 - val_loss: 0.0299\n",
            "Test Accuracy: 0.9902\n"
          ]
        }
      ],
      "source": [
        "#6. Using keras, build and train a simple CNN model on the MNIST dataset\n",
        "#from scratch. Include code for module creation, compilation, training, and evaluation.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 2. Preprocess data\n",
        "# Reshape to (samples, height, width, channels)\n",
        "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# 3. Build CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')  # 10 classes for digits 0–9\n",
        "])\n",
        "\n",
        "# 4. Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 5. Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=128,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    verbose=1)\n",
        "\n",
        "# 6. Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Load and preprocess the CIFAR-10 dataset using Keras, and create a\n",
        "#CNN model to classify RGB images. Show your preprocessing and architecture.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load CIFAR-10 dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# 2. Preprocess data\n",
        "# Normalize pixel values (0–255 → 0–1)\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode labels (10 classes)\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Test data shape:\", X_test.shape)\n",
        "\n",
        "# 3. Build CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')  # 10 classes\n",
        "])\n",
        "\n",
        "# 4. Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 5. Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    verbose=1)\n",
        "\n",
        "# 6. Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR6et2QU0D3n",
        "outputId": "29d73436-1f65-462e-ba0c-285fcfea9133"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 0us/step\n",
            "Training data shape: (50000, 32, 32, 3)\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 94ms/step - accuracy: 0.2798 - loss: 1.9333 - val_accuracy: 0.5147 - val_loss: 1.3405\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 89ms/step - accuracy: 0.4974 - loss: 1.3868 - val_accuracy: 0.5875 - val_loss: 1.1543\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 91ms/step - accuracy: 0.5746 - loss: 1.2101 - val_accuracy: 0.6294 - val_loss: 1.0468\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 91ms/step - accuracy: 0.6202 - loss: 1.0822 - val_accuracy: 0.6566 - val_loss: 0.9811\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 91ms/step - accuracy: 0.6540 - loss: 0.9906 - val_accuracy: 0.6719 - val_loss: 0.9313\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 89ms/step - accuracy: 0.6782 - loss: 0.9203 - val_accuracy: 0.6860 - val_loss: 0.9034\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 90ms/step - accuracy: 0.7000 - loss: 0.8566 - val_accuracy: 0.6992 - val_loss: 0.8650\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 90ms/step - accuracy: 0.7157 - loss: 0.8195 - val_accuracy: 0.7103 - val_loss: 0.8347\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 88ms/step - accuracy: 0.7331 - loss: 0.7599 - val_accuracy: 0.7078 - val_loss: 0.8473\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 91ms/step - accuracy: 0.7501 - loss: 0.7197 - val_accuracy: 0.7239 - val_loss: 0.8214\n",
            "Test Accuracy: 0.7239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Using PyTorch, write a script to define and train a CNN on the MNIST\n",
        "#dataset. Include model definition, data loaders, training loop, and accuracy evaluation.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. Data loaders (MNIST)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # mean and std for MNIST\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# 3. Define CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)   # input channels=1 (grayscale), output=32\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)  # output=64\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 128)          # after conv+pool, image size reduced\n",
        "        self.fc2 = nn.Linear(128, 10)                  # 10 classes for digits\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 5 * 5)  # flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "# 4. Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 5. Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# 6. Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7Q0ryKE0OBs",
        "outputId": "30ab0508-1ca0-428b-d5fe-cbae80c0ef8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.90MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 127kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.24MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.91MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.1342\n",
            "Epoch [2/5], Loss: 0.0433\n",
            "Epoch [3/5], Loss: 0.0293\n",
            "Epoch [4/5], Loss: 0.0221\n",
            "Epoch [5/5], Loss: 0.0162\n",
            "Test Accuracy: 98.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Given a custom image dataset stored in a local directory, write code using\n",
        "#Keras ImageDataGenerator to preprocess and train a CNN model.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# --- FIX: Create dummy directories and files for demonstration ---\n",
        "# This section creates dummy data to ensure the code runs without FileNotFoundError.\n",
        "# In a real scenario, you would replace this with your actual dataset.\n",
        "\n",
        "# Define dataset paths\n",
        "train_dir = \"data/train\"\n",
        "val_dir   = \"data/val\"\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(os.path.join(train_dir, 'class_a'), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, 'class_b'), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'class_a'), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'class_b'), exist_ok=True)\n",
        "\n",
        "# Create dummy images\n",
        "def create_dummy_image(path, size=(64, 64), color=(0, 0, 0)):\n",
        "    img = Image.new('RGB', size, color)\n",
        "    img.save(path)\n",
        "\n",
        "for i in range(10):\n",
        "    create_dummy_image(os.path.join(train_dir, 'class_a', f'img_{i}.png'), color=(255, 0, 0))\n",
        "    create_dummy_image(os.path.join(train_dir, 'class_b', f'img_{i}.png'), color=(0, 255, 0))\n",
        "for i in range(2):\n",
        "    create_dummy_image(os.path.join(val_dir, 'class_a', f'val_img_{i}.png'), color=(255, 0, 0))\n",
        "    create_dummy_image(os.path.join(val_dir, 'class_b', f'val_img_{i}.png'), color=(0, 255, 0))\n",
        "\n",
        "# --- End of FIX ---\n",
        "\n",
        "# 2. Create ImageDataGenerators with preprocessing & augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,          # normalize pixel values\n",
        "    rotation_range=20,       # random rotations\n",
        "    width_shift_range=0.2,   # horizontal shifts\n",
        "    height_shift_range=0.2,  # vertical shifts\n",
        "    shear_range=0.2,         # shear transformations\n",
        "    zoom_range=0.2,          # zoom\n",
        "    horizontal_flip=True,    # flip images\n",
        "    fill_mode='nearest'      # fill missing pixels after transforms\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 3. Create data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(64, 64),    # resize all images to 64x64\n",
        "    batch_size=32,\n",
        "    class_mode='categorical' # use 'binary' for 2 classes\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# 4. Build CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')  # output layer\n",
        "])\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 6. Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "# 7. Evaluate the model\n",
        "loss, acc = model.evaluate(val_generator, verbose=0)\n",
        "print(f\"Validation Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIrqNM2K0UxO",
        "outputId": "0a49ba82-37ab-4feb-d5ee-f2453b9f82bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 images belonging to 2 classes.\n",
            "Found 4 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.5000 - loss: 0.7419 - val_accuracy: 1.0000 - val_loss: 0.0343\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0490 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 7.5397e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 6.9141e-06\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 8.4519e-06 - val_accuracy: 1.0000 - val_loss: 7.7486e-07\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 1.3834e-05 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 8.3653e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 3.7848e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 4.1723e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 1.1152e-04 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Validation Accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}